{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it better to make 'subfunctions'; this allows for fine-tuning of output, as well as troubleshooting of specific steps.\n",
    "\n",
    "In 'real world', you have to be careful about malicious injections or horrifically invalid inputs. I typically make a single function to get input and verify it. I'm not nearly as rigid here as I would be otherwise, but I still have some validation for user inputs.\n",
    "\n",
    "Since we are querying a database we don't control, we also have to account for issues and variations in the database itself. PubMed unfortunately has some information in multiple potential fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components of Problem:\n",
    "-   Query NCBI database - can use Entez from Biopython to interact with the API\n",
    "    -   Requires an Email **(INPUT)**\n",
    "    -   Requires search query **(INPUT)**\n",
    "        -   Per instructions, query consists of a keyword and date range **(INPUT)**\n",
    "-   Minimum information for each article\n",
    "    -   Title\n",
    "    -   Abstract\n",
    "    -   Publication Date\n",
    "    -   Authors\n",
    "        - In next step, will need to be able to query authors\n",
    "-   Return information in a CSV file **(OUTPUT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking ahead to Step 2 of project:**\n",
    "\n",
    "Database Needs:\n",
    "-   **PMID** is likely to be a sufficient `key` for the SQL database of articles\n",
    "-   Need to be able to query by **author name**\n",
    "-   The relationship between authors and articles is MANY TO MANY (authors have more than one publication, and publications can have more than one article)\n",
    "-   Two cross-linked tables are required\n",
    "\n",
    "Author Data Table:\n",
    "-   Should separate first and last name - can either search one field, or the joined version in SQL querying\n",
    "    -   This should account for people with multiple names in a single field, or with a missing value in one field\n",
    "-   Generate an `Author ID (key)` for each unique combination as an arbitrary numbering (?)\n",
    "\n",
    "Article Data Table:\n",
    "-   Required:\n",
    "    -   `PMID (key)` - appears to be integers, but will need to verify from CSV file\n",
    "    -   Title - strings, which can contain some special characters (spaces, commas, colons, semicolons, etc)\n",
    "    -   Abstract - VERY LONG strings (paragraphs), which can contain some special characters\n",
    "    -   Publication Date - Date/Time, or we can pass it as a string\n",
    "-   Considerations:\n",
    "    -   Number of authors? This could simplify querying, and it is unique to each paper\n",
    "    -   Additional information, such as Journal Name, Journal Abbreviation, Langugage, Volume, Issue, Keywords, DOI, Pages\n",
    "\n",
    "Separate Table matching Authors and Papers:\n",
    "-   Combination key of `PMID` and `Author ID`\n",
    "-   Can also contain a TRUE/FALSE for 'First Author'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of a PubMed Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = 'apatheticgraffiti@gmail.com'\n",
    "try:\n",
    "    handle = Entrez.efetch(db = 'pubmed',\n",
    "                            retmode = 'xml',\n",
    "                            id = 32019336\n",
    "                            )\n",
    "                        \n",
    "    results = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    test_record = results\n",
    "except Exception as e:\n",
    "    message = ' '.join(['An error occured when contacting NCBI servers.',\n",
    "                        'Check your query terms. Consider reattempting',\n",
    "                        'outside of peak hours. Message: \\n',\n",
    "                        f'{e}'])\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   XML records act as Dictionary Objects with nested components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Entrez.Parser.DictionaryElement"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   'PubmedBookArticle' (irrelevant to our project)\n",
    "-   'PubmedArticle'\n",
    "    -   List of ['MedlineCitation' (Dictionary Object), 'PubmedData' (Dictionary Object)] items, for each ID used in query; can be iterated over\n",
    "    -   'PubmedArticle' contains the references, history, publication status, and article IDs associated with the article; none of this is useful to us\n",
    "    -   'MedlineCitation' contains ['KeywordList', 'GeneralNote', 'SpaceFlightMission', 'CitationSubset', 'OtherID', 'OtherAbstract', 'PMID', 'DateCompleted', 'DateRevised', 'Article', 'MedlineJournalInfo', 'ChemicalList', 'MeshHeadingList']. This is all the information we should require.\n",
    "\n",
    "As such, we can select `['PubmedArticle'][*idindexinlist*]['MedlineCitation']` for all records\n",
    "\n",
    "-   **'KeywordList'** is either empty (len = 0) or contains a list of keywords\n",
    "    -   Can join into a string with `', '. join(record['PubmedArticle'][0]['MedlineCitation']['KeywordList'])`\n",
    "-   'GeneralNote', 'SpaceFlightMission', 'CitationSubset', 'OtherID', and 'OtherAbstract' are irrelevant to our project\n",
    "-   **'PMID'** contains the PMID used in query as a special String element\n",
    "    -   Can be extracted with `str(record['PubmedArticle'][0]['MedlineCitation']['PMID'])`\n",
    "-   'DateCompleted' is a dictionary with keys ['Year', 'Month', 'Day']; may be useful if no other dates found\n",
    "-   'DateRevised' is a dictionary with ['Year', 'Month', 'Day']; but likely irrelevant to the project\n",
    "-   **'Article'** is a dictionary object with keys ['ArticleDate', 'Language', 'ELocationID', 'Journal', 'ArticleTitle', 'Pagination', 'Abstract', 'AuthorList', 'GrantList', 'PublicationTypeList']\n",
    "    -   **'ArticleDate' is the preferred publication date**; Dictionary Object ['Year', 'Month', 'Day'] keys, but may be missing components or entirely missing. May also have Months in 3 character strings (e.g. 'Feb' instead of '02').\n",
    "    -   **'Language'** is gives a list element, with **language of the article in standard abbreviation** (e.g., English is 'eng')\n",
    "        -  Can be extracted with `', '. join(record['PubmedArticle'][*index*]['MedlineCitation']['Article']['Language'])`\n",
    "    -   **'ELocationID'** is a list of string elements with attributes\n",
    "        -  Can identify valid **DOI** with `record['PubmedArticle'][*index*]['MedlineCitation']['Article']['ELocationID'][*index*].attributes['EIdType'] == 'doi' and test_record['PubmedArticle'][*index*]['MedlineCitation']['Article']['ELocationID'][*index*].attributes['ValidYN'] == 'Y'`; extract with `str(record['PubmedArticle'][*index*]['MedlineCitation']['Article']['ELocationID']`\n",
    "    -   'Journal' is a dictionary with keys '[ISSN','JournalIssue','ISOAbbreviation']\n",
    "        -   'ISSN' is likely irrelevant to our project\n",
    "        -   'JournalIssue' is a dictionary with keys ['Volume', 'Issue', 'PubDate']\n",
    "            -   'Volume' gives the volume, if it exists at all\n",
    "            -   'Issue' gives the issue, if it exists at all\n",
    "            -   'PubDate' is a dictionary with keys ['Year', 'Month', 'Day'], with similar problems to 'DateCompleted' above - this is the preferred DATE, but may be missing components or otherwise absent\n",
    "        -   **'ISOAbbreviation'** gives the journal name's **standardized abbreviation**\n",
    "    -   **'ArticleTitle'** gives the title as a string\n",
    "    -   **'Pagination'** is a dictionary with keys ['StartPage', 'EndPage', 'MedlinePgn']\n",
    "        -   All are strings, but may be absent or otherwise missing; 'StartPage' and 'EndPage' are prefered, with extraction from 'MedlinePgn' if absent\n",
    "    -   **'Abstract'** is a dictionary with key ['AbstractText], which is a list of strings.\n",
    "        -  Can be extracted with `' '. join(record['PubmedArticle'][*index*]['MedlineCitation']['Article']['Abstract']['AbstractText])`\n",
    "    -   **'AuthorList'** is a list of dictionaries with keys ['AffiliationInfo', 'Identifier', 'LastName', 'ForeName', 'Initials']\n",
    "        -   'AffiliationInfo' is irrelevant for our project\n",
    "        -   'Identifier' is usually blank\n",
    "        -   'LastName' is last names\n",
    "        -   'ForeName' is first names, which may be missing\n",
    "        -   'Initials' are initials preceeding first name, which may be missing\n",
    "    -   'GrantList' and 'PublicationTypeList' are irrelevant for the project\n",
    "-   'MedlineJournalInfo' is a dictionary containing keys ['Country', 'MedlineTA', 'NlmUniqueID']; all are irrelevant to the project\n",
    "-   'ChemicalList' is a list of dictionaries with keys ['RegistryNumber', 'NameOfSubstance']; all are irrelevant to our project\n",
    "-   'MeshHeadingList' is a list of dictionaries with keys ['QualifierName', 'DescriptorName']; all are irrelevant to our project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListElement([StringElement('CXCR4', attributes={'MajorTopicYN': 'N'}), StringElement('HIV-1 entry inhibitor', attributes={'MajorTopicYN': 'N'}), StringElement('V3 loop', attributes={'MajorTopicYN': 'N'}), StringElement('X4-tropic', attributes={'MajorTopicYN': 'N'}), StringElement('gp120', attributes={'MajorTopicYN': 'N'})], attributes={'Owner': 'NOTNLM'})"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_record['PubmedArticle'][0]['MedlineCitation']['KeywordList'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan for Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top level content:\n",
    "-   PMID from ['PMID']\n",
    "    - otherwise use query ID if a record was returned at all\n",
    "-   Keywords from joining items in ['KeywordList'] if they exist with length > 0\n",
    "    - otherwise empty\n",
    "Content from ['Article']\n",
    "-   Title from ['Article']['ArticleTitle']\n",
    "-   Abstract from joining ['Article']['Abstract']['AbstractText'] if ['Article']['Abstract']['AbstractText'] exists and has a length > 0\n",
    "    - otherwise empty\n",
    "-   Authors from carefully joining elements of ['Article']['AuthorList']\n",
    "    - LAST, FIRST order, with items blank if entirely missing. If ForeName missing, use Initials\n",
    "-   Date from ['Article']['ArticleDate'] in Y/M/D format \n",
    "    - Format will automatically will default 'up' for missing components, so missing month is jan, missing day is the first, etc.\n",
    "    - If missing, try date from ['Journal']\n",
    "-   Language from joining ['Article']['Language'] if ['Article']['Language'] exists and has a length > 0\n",
    "    - otherwise empty\n",
    "-   Pagination from ['Article']['Pagination'] if it exists and has length > 0\n",
    "    - First and Last as separate; use the combined version if those are absent\n",
    "    - otherwise blank\n",
    "-   Content from ['Article']['Journal']\n",
    "    -   Abbreviation from ['Article']['Journal']['ISOAbbreviation'] if it exists and has length > 0\n",
    "    -   Journal name in ['Article']['Journal']['Title'] if it exists and has a length > 0 \n",
    "    -   Issue from ['Article']['Journal']['JournalIssue']['Issue'] if it exists and has length > 0\n",
    "    -   Volume from ['Article']['Journal']['JournalIssue']['Volume'] if it exists and has length > 0\n",
    "    -   Date from ['Article']['Journal']['JournalIssue']['PubDate'], prefered over ['Article']['ArticleDate'] - same caveats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for output format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall needs:\n",
    "-   Establish a format for creating this CSV where each article is only one line\n",
    "-   Delimiter of CSV needs to be unique enough that it wont cause issues in the text fields with special characters (Title, Abstract)\n",
    "-   Need 1 row for each article, despite multiple authors: need to create a list of authors with two delimiters (between first/last field, and between authors)\n",
    "\n",
    "CSV Delimiter: ','\n",
    "\n",
    "Author Delimiters: '+' between authors, ';;' between fields in (last;;first) order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Each line is a single row\n",
    "-   No header\n",
    "\n",
    "PMID, PUBLICATIONDATE, TITLE, JOURNALNAME, JOURNALABBREVIATION, VOL, ISSUE, KEYWORDS, AUTHORS[LAST;;FIRST+LAST;;FIRST] LANGUAGE, FIRSTPAGE, LASTPAGE, ABSTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from datetime import datetime as dt\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Search, Retrieve IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_search_ids(keyword, start_date, end_date, email):\n",
    "    \"\"\"\n",
    "    Submits a query to PubMed via ENTREZ\n",
    "    \n",
    "    INPUTS:\n",
    "        keyword (string): Keyword term\n",
    "        start_date (string): Date in YYYY/MM/DD format\n",
    "        end_date (string): Date in YYYY/MM/DD format\n",
    "        email (string): email address, required by NCBI\n",
    "    RETURNS:\n",
    "        results (list): list of PMIDs as strings\n",
    "        Prints error message and suggestions if error message from\n",
    "        NCBI\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        Entrez from BioPython\n",
    "    \"\"\"\n",
    "\n",
    "    query = (f'({keyword}) AND (\"{start_date}\"[Date - Publication]'\n",
    "            f' : \"{end_date}\"[Date - Publication])'\n",
    "            )\n",
    "\n",
    "    Entrez.email = email\n",
    "    try:\n",
    "        handle = Entrez.esearch(db='pubmed',\n",
    "                                sort='relevance',\n",
    "                                retmax = 200000,\n",
    "                                retmode='xml',\n",
    "                                term=query)\n",
    "        results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        return results['IdList']\n",
    "    except Exception as e:\n",
    "        message = ' '.join(['An error occured when contacting NCBI servers.',\n",
    "                            'Check your query terms. Consider reattempting',\n",
    "                            'outside of peak hours. Message: \\n',\n",
    "                            f'{e}'])\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fetch a Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_details(target_ids, email):\n",
    "    \"\"\"\n",
    "    Queries IDs from PubMed\n",
    "    Automatically trims output to the Medline Citation\n",
    "\n",
    "    INPUTS:\n",
    "        Keyword (string): Keyword term\n",
    "        start_date (string): Date in YYYY/MM/DD format\n",
    "        end_date (string): Date in YYYY/MM/DD format\n",
    "        email (string): email address, required by NCBI\n",
    "    RETURNS:\n",
    "        results (list): list of MedlineCitation entries in each result\n",
    "        Prints error message and suggestions if error message from\n",
    "        NCBI\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        Entrez from BioPython\n",
    "    \"\"\"\n",
    "    Entrez.email = email\n",
    "    try:\n",
    "        handle = Entrez.efetch(db = 'pubmed',\n",
    "                            retmode = 'xml',\n",
    "                            id = target_ids)\n",
    "                            \n",
    "        results = [result['MedlineCitation'] for result in Entrez.read(handle)['PubmedArticle']]\n",
    "        handle.close()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        message = ' '.join(['An error occured when contacting NCBI servers.',\n",
    "                            'Check your query terms. Consider reattempting',\n",
    "                            'outside of peak hours. Message: \\n',\n",
    "                            f'{e}'])\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract Data from a record, to make a row of output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting and Formatting Dates and Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date_obj):\n",
    "    \"\"\"\n",
    "    Takes a date object and returns a formatted date time object\n",
    "\n",
    "    INPUTS:\n",
    "        date_obj (dict): Dictionary, which may contain keys\n",
    "                        ['Year', 'Month', 'Day'] with single\n",
    "                        string content.\n",
    "                        'Year' is expected to be 4 digit, if exists\n",
    "                        'Month' is expected to be 2 digit or\n",
    "                                3 character string, if exists\n",
    "                        'Day' is expected to be 2 digit, if exists\n",
    "    RETURNS:\n",
    "        date (date): Date, with missing/invalid month or day\n",
    "                     rounded to '01'.\n",
    "                     Returns an empty string if invalid, or \n",
    "                     no year.\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        datetime.datetime as dt\n",
    "    \"\"\"\n",
    "    # Dictionary to translate string months\n",
    "    months_dict = {\n",
    "                'jan': '01', 'feb': '02', 'mar': '03', \n",
    "                'apr': '04', 'may': '05', 'jun': '06' ,\n",
    "                'jul': '07', 'aug': '08', 'sep': '09', \n",
    "                'oct': '10', 'nov': '11', 'dec': '12',\n",
    "                }\n",
    "\n",
    "    # YEAR\n",
    "    if 'Year' in date_obj.keys():\n",
    "        year = date_obj['Year'].lower().strip()\n",
    "        if len(year) < 4 or not year.isdigit():\n",
    "            year = False\n",
    "    else:\n",
    "        year = False\n",
    "    # MONTH\n",
    "    if 'Month' in date_obj.keys():\n",
    "        month = date_obj['Month'].lower().strip()\n",
    "        if not month.isdigit() and month in months_dict.keys():\n",
    "            month = months_dict[month]\n",
    "        elif month.isdigit() and int(month) in range(1,13) and len(month) < 2:\n",
    "            month = '0' + str(int(month))\n",
    "        else:\n",
    "            month = False\n",
    "    else:\n",
    "        month = False\n",
    "    # DAY\n",
    "    if 'Day' in date_obj.keys():\n",
    "        day = date_obj['Day'].lower().strip()\n",
    "        if day.isdigit() and int(day) in range(1,13) and len(day) < 2:\n",
    "            day = '0' + str(int(day))\n",
    "        else:\n",
    "            day = False\n",
    "    else:\n",
    "        day = False\n",
    "\n",
    "    # Format\n",
    "    if year and month and day:\n",
    "        date = dt.strptime(f'{year}/{month}/{day}', r'%Y/%m/%d').date()\n",
    "    elif year and month:\n",
    "        date = dt.strptime(f'{year}/{month}', r'%Y/%m').date()\n",
    "    elif year and day:\n",
    "        date = dt.strptime(f'{year}/{day}', r'%Y/%d').date()\n",
    "    elif year:\n",
    "        date = dt.strptime(f'{year}', r'%Y').date()\n",
    "    else:\n",
    "        date = ''\n",
    "\n",
    "    # Return\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_author(record, delimiter = '+'):\n",
    "    \"\"\"\n",
    "    Formats an Author from a PubMed Author List into a string\n",
    "    in 'FIRST (delimiter) LAST (delimiter) INITIALS' format,\n",
    "    all in lowercase\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): Single entry from a PubMed MedlineCitation \n",
    "                already sliced to ['Article']['AuthorList'].\n",
    "                Expected to potentially contain the single values\n",
    "                for keys []'ForeName', 'LastName', 'Initials']\n",
    "        delimiter (str): delimiter between components in the \n",
    "                output string. Default is '+' \n",
    "    RETURNS:\n",
    "        name_str (str): string listing of author name\n",
    "                missing fields are blank. If ForeName absent,\n",
    "                attempts to replace with Initials\n",
    "    \"\"\"\n",
    "    if 'ForeName' in record.keys() and len(record['ForeName']) > 0:\n",
    "        first_nm = record['ForeName'].lower().strip()\n",
    "    elif 'Initials' in record.keys() and len(record['Initials']) > 0:\n",
    "        first_nm = record['Initials'].lower().strip()\n",
    "    else:\n",
    "        first_nm = ''\n",
    "    if 'Initials' in record.keys() and len(record['Initials']) > 0:\n",
    "        initials = record['Initials'].lower().strip()\n",
    "    else:\n",
    "        initials = ''\n",
    "\n",
    "    if 'LastName' in record.keys() and len(record['LastName']) > 0:\n",
    "        last_nm = record['LastName'].lower().strip()\n",
    "    else:\n",
    "        last_nm = ''\n",
    "\n",
    "    name_str = delimiter.join([first_nm,last_nm,initials])\n",
    "\n",
    "    return name_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Journal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def journal_content(record, extract_date = False):\n",
    "    \"\"\"\n",
    "    Scrapes ['Article']['Journal'] level content from\n",
    "    a PubMed MedlineCitation entry:\n",
    "    Journal Title, Journal ISO Abbreviation, Volume, Issue,\n",
    "    and Publication Date\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): PubMed MedlineCitation already sliced to\n",
    "                ['Article']['Journal']\n",
    "        extract_date (bool): TRUE if extraction of date is\n",
    "                desired; default is FALSE \n",
    "    RETURNS:\n",
    "        jour_data (list): list of ['Journal'] data items;\n",
    "                [Journal Title, Journal ISO Abbreviation,\n",
    "                Volume, Issue, Publication Date]\n",
    "                missing fields are empty strings\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        format_date(): datetime.datetime as dt\n",
    "    \"\"\"\n",
    "    # JOURNAL NAME\n",
    "    if 'Title' in record.keys() and len(record['Title']) >0:\n",
    "        jour_title = str(record['Title']).lower().strip()\n",
    "    else:\n",
    "        jour_title = ''\n",
    "\n",
    "    # JOURNAL ABBREVIATION\n",
    "    if 'ISOAbbreviation' in record.keys() and len(record['ISOAbbreviation']) >0:\n",
    "        jour_abbrev = str(record['ISOAbbreviation']).lower().strip()\n",
    "    else:\n",
    "        jour_abbrev = ''\n",
    "\n",
    "    # Journal Issue Items\n",
    "    if 'JournalIssue' in record.keys():\n",
    "    # JOURNAL ISSUE\n",
    "        if 'Issue' in record['JournalIssue'].keys() and len(record['JournalIssue']['Issue']) >0:\n",
    "            jour_issue = str(record['JournalIssue']['Issue']).lower().strip()\n",
    "        else:\n",
    "            jour_issue = ''\n",
    "    # JOURNAL VOLUME\n",
    "        if 'Volume' in record['JournalIssue'].keys() and len(record['JournalIssue']['Volume']) >0:\n",
    "            jour_vol = str(record['JournalIssue']['Volume']).lower().strip()\n",
    "        else:\n",
    "            jour_vol = ''\n",
    "    # JOURNAL DATE\n",
    "        if extract_date:\n",
    "            if 'PubDate' in record['JournalIssue'].keys() and len(record['JournalIssue']['PubDate']) >0:\n",
    "                jour_date = format_date(record['JournalIssue']['PubDate'])\n",
    "            else:\n",
    "                jour_date = ''\n",
    "        else:\n",
    "            jour_date = ''\n",
    "    else:\n",
    "        jour_vol = ''\n",
    "        jour_issue = ''\n",
    "        jour_date = ''\n",
    "\n",
    "    jour_data = [jour_title, jour_abbrev, jour_vol, jour_issue, jour_date]\n",
    "\n",
    "    return jour_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_content(record, delimiter_btwn = '+', delimiter_within = ';;', \n",
    "                    date_format = r'%Y/%m/%d'):\n",
    "    \"\"\"\n",
    "    Scrapes ['Article'] level content from\n",
    "    a PubMed MedlineCitation entry:\n",
    "    Title, Abstract, Pageination, Publication Date, Language,\n",
    "    Authors, Journal Title, Journal ISO Abbreviation,\n",
    "    Journal Volume, Journal Issue.\n",
    "    Prefers JOURNAL PUBLICATION DATE over Article Date, if\n",
    "    it is present.\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): PubMed MedlineCitation already sliced to\n",
    "                ['Article']\n",
    "        delimiter_btwn (str): delimiter betwen authors in the\n",
    "                author list; default is '+'\n",
    "        delimiter_within (str): delimiter betwen components\n",
    "                of author name, used in format_author(); \n",
    "                default is ';;'\n",
    "        date_format (str): string for date format using datetime\n",
    "                object. Default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "    RETURNS:\n",
    "        article_data (list): list of ['Article'] data items;\n",
    "                [Article Title, Article Abstract, Publication Date,\n",
    "                Start Page, End Page, Language, Authors, Journal Title,\n",
    "                Journal ISO Abbreviation, Journal Volume, Journal Issue]\n",
    "                Missing fields are empty strings\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        datetime.datetime as dt\n",
    "        format_date()\n",
    "        format_author(): re\n",
    "        journal_content()\n",
    "    \"\"\"\n",
    "\n",
    "    # TITLE\n",
    "    if 'ArticleTitle' in record.keys() and len(record['ArticleTitle']) >0:\n",
    "        title = str(record['ArticleTitle']).lower().strip()\n",
    "    else:\n",
    "        title = ''\n",
    "\n",
    "    # ABSTRACT\n",
    "    if 'Abstract' in record.keys() and len(record['Abstract']) >0:\n",
    "        if 'AbstractText' in record['Abstract'].keys() and len(record['Abstract']['AbstractText']) > 0:\n",
    "            abstract = ' '.join(record['Abstract']['AbstractText'])\n",
    "        else:\n",
    "            abstract = ''\n",
    "    else:\n",
    "        abstract = ''\n",
    "\n",
    "    # DATE (IF NOT WITH JOURNAL)\n",
    "    if 'ArticleDate' in record.keys() and len(record['ArticleDate']) >0:\n",
    "        date = format_date(record['ArticleDate'][0])\n",
    "    else:\n",
    "        date = ''\n",
    "\n",
    "    # PAGINATION\n",
    "    pgn_regex = r'^([0-9a-z]+)(?:[ -:/]+?)([0-9a-z]+)$'\n",
    "    if 'Pagination' in record.keys() and len(record['Pagination']) >0:\n",
    "        if 'StartPage' in record['Pagination'].keys() and len(record['Pagination']['StartPage']) > 0:\n",
    "            page_start = record['Pagination']['StartPage']\n",
    "        else:\n",
    "            page_start = False\n",
    "        if 'EndPage' in record['Pagination'].keys() and len(record['Pagination']['EndPage']) > 0:\n",
    "            page_end = record['Pagination']['EndPage']\n",
    "        else:\n",
    "            page_end = False\n",
    "        if not (page_start or page_end):\n",
    "            if 'MedlinePgn' in record['Pagination'].keys() and len(record['Pagination']['MedlinePgn']) > 0:\n",
    "                search = re.search(pgn_regex, record['Pagination']['MedlinePgn'])\n",
    "                if search:\n",
    "                    page_start = search[1]\n",
    "                    page_end = search[2]\n",
    "        # If still not valid, just make empty strings\n",
    "        if not (page_start or page_end):\n",
    "            page_start = ''\n",
    "            page_end = ''\n",
    "    else:\n",
    "        page_start = ''\n",
    "        page_end = ''\n",
    "\n",
    "\n",
    "    # AUTHORS\n",
    "    if 'AuthorList' in record.keys() and len(record['AuthorList']) > 0:\n",
    "        authors = delimiter_btwn.join([format_author(author, delimiter_within) for author in record['AuthorList']])\n",
    "    else:\n",
    "        authors = ''\n",
    "\n",
    "    # LANGUAGE\n",
    "    if 'Language' in record.keys() and len(record['Language']) > 0:\n",
    "        lang = ', '.join(record['Language'])\n",
    "    else:\n",
    "        lang = ''\n",
    "\n",
    "    # ['Journal'] CONTENT\n",
    "    jour_content = journal_content(record['Journal'], extract_date = True)\n",
    "    jour_title, jour_abbrev, jour_vol, jour_issue, jour_date = jour_content\n",
    "\n",
    "    # PREFER DATE FROM JOURNAL\n",
    "    if jour_date != '':\n",
    "        date = jour_date\n",
    "    if date != '':\n",
    "        date = date.strftime(date_format)\n",
    "\n",
    "    # Package Output\n",
    "\n",
    "    article_content = [title, abstract, date, page_start,\n",
    "                        page_end, lang, authors, jour_title, \n",
    "                        jour_abbrev, jour_vol, jour_issue\n",
    "                        ]\n",
    "    # Return Output\n",
    "    return article_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Full Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_record(record, name_delim_btwn = '+', name_delim_within = ';;', \n",
    "                  date_format = r'%Y/%m/%d'):\n",
    "    \"\"\"\n",
    "    Scrapes a MedlineCitation of a PubMed article.\n",
    "    Returns article data as a list, which can become a single row \n",
    "    of a dataframe or other structure.\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): PubMed MedlineCitation\n",
    "        name_delimi_btwn (str): delimiter betwen authors in the\n",
    "                author list, used in article_content(); \n",
    "                default is '+'\n",
    "        name_delim_within (str): delimiter betwen components\n",
    "                of author name, used in format_author() within\n",
    "                article_content(); default is ';;'\n",
    "        date_format (str): string for date format using datetime\n",
    "                object in article_content(); \n",
    "                default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "    RETURNS:\n",
    "        content (list): list of article data;\n",
    "                [PMID, Publication Date, Article Title,\n",
    "                Journal Title, Journal ISO Abbreviation, \n",
    "                Journal Volume, Journal Issue, Keywords, \n",
    "                Authors, Language, Pagination (Start),\n",
    "                Pagination (End), Abstract]\n",
    "                Missing fields are empty strings\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        datetime.datetime as dt\n",
    "        format_date()\n",
    "        format_author(): re\n",
    "        journal_content()\n",
    "        article_content()\n",
    "    \"\"\"\n",
    "    # PMID\n",
    "    if 'PMID' in record.keys() and len(record['PMID']) > 0:\n",
    "        pmid = str(record['PMID']).lower().strip()\n",
    "    else:\n",
    "        pmid = ''\n",
    "    # KEYWORDS\n",
    "    if 'KeywordList' in record.keys() and len(record['KeywordList']) > 0:\n",
    "        keywords = name_delim_btwn.join([', '.join(keywords) for keywords in record['KeywordList']])\n",
    "    else:\n",
    "        keywords = ''\n",
    "\n",
    "    # ARTICLE CONTENT\n",
    "    article = [i for i in article_content(record['Article'], name_delim_btwn, name_delim_within, date_format)]\n",
    "    title, abstract, date, page_start = article[0:4]\n",
    "    page_end, lang, authors, jour_title = article[4:8]\n",
    "    jour_abbrev, jour_vol, jour_issue = article[8:11]\n",
    "\n",
    "    # Organize Output into row\n",
    "    content = [pmid, date, title, jour_title, jour_abbrev,\n",
    "            jour_vol, jour_issue, keywords, authors,\n",
    "            lang, page_start, page_end, abstract]\n",
    "    \n",
    "    # Return\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Scrape Multiple Records in Chunks, Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_process(keyword, start_date, end_date, email, \n",
    "                  path, chunksize = 100, date_format = r'%Y/%m/%d',\n",
    "                  name_delim_btwn = '+', name_delim_within = ';;', \n",
    "                  delim = ',', quote_str = '|', overwrite = False):\n",
    "    \"\"\"\n",
    "    Performs a search of PubMed using a date range and keyword,\n",
    "    and scrapes these records into a CSV file.\n",
    "\n",
    "    INPUTS:\n",
    "        keyword (string): Keyword term\n",
    "        start_date (string): Date in YYYY/MM/DD format\n",
    "        end_date (string): Date in YYYY/MM/DD format\n",
    "        email (string): email address, required by NCBI\n",
    "        path (string,path): string address of output file path\n",
    "        chunksize (int): number of records to batch process\n",
    "                between opening file, used to optimize run time\n",
    "                based on capabilities of an individual machine;\n",
    "                default is 100\n",
    "        date_format (str): string for date format using datetime\n",
    "                object in article_content(); \n",
    "                default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "        name_delimi_btwn (str): delimiter betwen authors in the\n",
    "                author list; \n",
    "                default is '+'\n",
    "        name_delim_within (str): delimiter betwen components\n",
    "                of author name; \n",
    "                default is ';;'\n",
    "        delim (str): delimiter between values in a single row\n",
    "                in the CSV output file. Must be a single\n",
    "                character string;\n",
    "                default is ','\n",
    "        quote_str (str): character used to quote entries that\n",
    "                contain characters in the delimiters;\n",
    "                default is '|'\n",
    "        overwrite (bool): True/False value indicating if it is\n",
    "                desired to overwrite the output file, if it\n",
    "                already exists;\n",
    "                default is FALSE\n",
    "\n",
    "    RETURNS:\n",
    "        writes records to `path`. Prints happy message summary\n",
    "        if successful. If error, prints error message and the row\n",
    "        where the problem occured.\n",
    "\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        os\n",
    "        csv\n",
    "        re\n",
    "        Entrez from BioPython\n",
    "        datetime.datetime as dt\n",
    "        pubmed_search_ids()\n",
    "        scrape_record()\n",
    "        journal_content()\n",
    "        article_content()\n",
    "        format_date()\n",
    "        format_author()\n",
    "    \"\"\"  \n",
    "    # Perform Search, Get IDS\n",
    "    target_ids = pubmed_search_ids(keyword, start_date, end_date, email)\n",
    "    # Chunk Data\n",
    "    if target_ids:\n",
    "        try:\n",
    "            for i in range (0, len(target_ids), chunksize):\n",
    "                chunk_ids = target_ids[i:i+chunksize]\n",
    "                records = fetch_details(chunk_ids, email)\n",
    "                data = [scrape_record(record,name_delim_btwn, name_delim_within, date_format) for record in records]\n",
    "                # If output file does not exist or overwrite = 'TRUE was called, create file\n",
    "                if not os.path.isfile(path) or overwrite:\n",
    "                    with open(path, 'w', encoding = 'utf-8') as outfile:\n",
    "                        csvwriter = csv.writer(outfile, delimiter = delim, quotechar = quote_str)\n",
    "                        for row in data:\n",
    "                            csvwriter.writerow(row)\n",
    "                # Otherwise, open for appending\n",
    "                else:\n",
    "                    with open(path,'a', encoding = 'utf-8') as outfile:\n",
    "                        csvwriter = csv.writer(outfile, delimiter = delim, quotechar = quote_str)\n",
    "                        for row in data:\n",
    "                            csvwriter.writerow(row)\n",
    "            # Happy Message\n",
    "            message = [f'Success! \\n {len(target_ids)} records for ',\n",
    "                    'PubMed Search: \\n',\n",
    "                    f'({keyword}) AND (\"{start_date}\"[Date - Publication]'\n",
    "                    f' : \"{end_date}\"[Date - Publication]) \\n',\n",
    "                    f' written to {path}']\n",
    "            print(''.join(message))\n",
    "        except Exception as e:\n",
    "            message = ['An error occured:', e, \n",
    "                    'Row with issue:', f'{row}']\n",
    "            print('\\n'.join(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Wrap with Basic Input Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapper(keyword = None, start_date = None, end_date = None,\n",
    "                    email = None, path = None, chunksize = 100,\n",
    "                    date_format = r'%Y/%m/%d',\n",
    "                    name_delim_btwn = '+', name_delim_within = ';;', \n",
    "                    delim = ',', quote_str = '|', overwrite = False):\n",
    "    \"\"\"\n",
    "    Validates inputs and runs scrapper!\n",
    "\n",
    "    INPUTS:\n",
    "        PROMPTS FOR INPUT IF MISSING OR INVALID:\n",
    "            keyword (string): Keyword term\n",
    "            start_date (string): Date in YYYY/MM/DD format\n",
    "            end_date (string): Date in YYYY/MM/DD format\n",
    "            email (string): email address, required by NCBI\n",
    "            path (string,path): string address of output file path\n",
    "        DOES NOT PROMPT OR VALIDATE, HAS DEFAULT:\n",
    "            chunksize (int): number of records to batch process\n",
    "                    between opening file, used to optimize run time\n",
    "                    based on capabilities of an individual machine;\n",
    "                    default is 100\n",
    "            date_format (str): string for date format using datetime\n",
    "                    object in article_content(); \n",
    "                    default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "            name_delimi_btwn (str): delimiter betwen authors in the\n",
    "                    author list; \n",
    "                    default is '+'\n",
    "            name_delim_within (str): delimiter betwen components\n",
    "                    of author name; \n",
    "                    default is ';;'\n",
    "            delim (str): delimiter between values in a single row\n",
    "                    in the CSV output file. Must be a single\n",
    "                    character string;\n",
    "                    default is ','\n",
    "            quote_str (str): character used to quote entries that\n",
    "                    contain characters in the delimiters;\n",
    "                    default is '|'\n",
    "            overwrite (bool): True/False value indicating if it is\n",
    "                    desired to overwrite the output file, if it\n",
    "                    already exists;\n",
    "                    default is FALSE\n",
    "    RETURNS:\n",
    "        writes records to `path`. Prints happy message summary\n",
    "        if successful. If error, prints error message and the row\n",
    "        where the problem occured.\n",
    "\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        os\n",
    "        csv\n",
    "        re\n",
    "        Entrez from BioPython\n",
    "        datetime from datetime as dt\n",
    "        chunk_process()\n",
    "        pubmed_search_ids()\n",
    "        scrape_record()\n",
    "        journal_content()\n",
    "        article_content()\n",
    "        format_date()\n",
    "        format_author()\n",
    "    \"\"\"\n",
    "    ########### DATA CHECKS ################\n",
    "    # =======================================      \n",
    "    email_regex = r\"^[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?$\"\n",
    "    # Allow user to exit\n",
    "    quit = False\n",
    "    while not quit:\n",
    "        ###### GET INPUTS IF NOT GIVEN IN FUNCTION\n",
    "        while not email:\n",
    "            email = input(\"Enter email for Entrez query, or 'q' to exit: \").lower().strip()\n",
    "            if email == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        if not keyword:\n",
    "            keyword = input(\"Enter keyword, or 'q' to exit: \").lower().strip()\n",
    "            if keyword == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        while not start_date:\n",
    "            start_date = input(\"Enter start date (YYYY/MM/DD), or 'q' to exit: \").strip().lower()\n",
    "            if start_date == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        while not end_date:\n",
    "            end_date = input(\"Enter end date (YYYY/MM/DD), or 'q' to exit: \").strip().lower()\n",
    "            if end_date == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        while not path:\n",
    "            # No .lower() because paths can be case sensitive\n",
    "            path = input(\"Enter path for output file (.txt or .csv), or 'q' to exit: \").strip()\n",
    "            if path == 'q' or 'Q':\n",
    "                quit = True\n",
    "                break\n",
    "        ###### VALIDATE\n",
    "        if email:\n",
    "            if not re.search(email_regex, email):\n",
    "                print(\"Invalid email.\")\n",
    "                email = None\n",
    "        if start_date:\n",
    "        # Checks start_date format, if this fails, it's invalid\n",
    "            try:\n",
    "                start_date = dt.strptime(start_date, r'%Y/%m/%d').date()\n",
    "            except:\n",
    "                print(\"Invalid start date.\")\n",
    "                start_date = None\n",
    "        if end_date:\n",
    "        # Checks end_date format, if this fails, it's invalid\n",
    "            try:\n",
    "                end_date = dt.strptime(end_date, r'%Y/%m/%d').date()\n",
    "            except:\n",
    "                print(\"Invalid date. Try again\")\n",
    "                end_date = None\n",
    "        # Ensure start_date is before end_date\n",
    "        if (start_date and end_date) and start_date > end_date:\n",
    "            print(f\"Start Date {start_date} is after {end_date}. Please enter valid dates\")\n",
    "            start_date = None\n",
    "            end_date = None\n",
    "        # Check path is valid\n",
    "        if path:\n",
    "            try:\n",
    "                path = os.path.abspath(path)\n",
    "                if not os.path.isdir(os.path.split(path)[0]):\n",
    "                    print(\"Path directory not found.\")\n",
    "                    path = None\n",
    "                if os.path.basename(path).split('.')[1] not in ('txt', 'csv'):\n",
    "                    print(\"File must have a .txt or .csv extension.\")\n",
    "                    path = None\n",
    "            except:\n",
    "                print(\"Invalid path\")\n",
    "                path = None\n",
    "        # Ensure String Format for dates\n",
    "        if start_date and end_date:\n",
    "            if not isinstance(start_date,str):\n",
    "                start_date = start_date.strftime(r'%Y/%m/%d')\n",
    "            if not isinstance(end_date, str):\n",
    "                end_date = end_date.strftime(r'%Y/%m/%d')\n",
    "        \n",
    "        # If all valid, break out of validation cycle!\n",
    "        if start_date and end_date and keyword and email and path:\n",
    "            break\n",
    "    if not quit:\n",
    "        chunk_process(keyword, start_date, end_date, email, \n",
    "                  path, chunksize, date_format,\n",
    "                  name_delim_btwn, name_delim_within, \n",
    "                  delim, quote_str, overwrite)\n",
    "    else:\n",
    "        print(\"Processing Stopped.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Wrapped in a Single Doc, with main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occured when contacting NCBI servers. Check your query terms. Consider reattempting outside of peak hours. Message: \n",
      " HTTP Error 500: Internal Server Error\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from datetime import datetime as dt\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "def main():\n",
    "    keyword = 'hiv'\n",
    "    start_date = '2020/01/01'\n",
    "    end_date = '2020/08/01'\n",
    "    email = 'morrigan.mahady@uth.tmc.edu'\n",
    "    path = 'outfile.txt'\n",
    "    chunksize = 200\n",
    "    scrapper(keyword, start_date, end_date, email, path, chunksize = chunksize)\n",
    "\n",
    "def pubmed_search_ids(keyword, start_date, end_date, email):\n",
    "    \"\"\"\n",
    "    Submits a query to PubMed via ENTREZ\n",
    "    \n",
    "    INPUTS:\n",
    "        keyword (string): Keyword term\n",
    "        start_date (string): Date in YYYY/MM/DD format\n",
    "        end_date (string): Date in YYYY/MM/DD format\n",
    "        email (string): email address, required by NCBI\n",
    "    RETURNS:\n",
    "        results (list): list of PMIDs as strings\n",
    "        Prints error message and suggestions if error message from\n",
    "        NCBI\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        Entrez from BioPython\n",
    "    \"\"\"\n",
    "\n",
    "    query = (f'({keyword}) AND (\"{start_date}\"[Date - Publication]'\n",
    "            f' : \"{end_date}\"[Date - Publication])'\n",
    "            )\n",
    "\n",
    "    Entrez.email = email\n",
    "    try:\n",
    "        handle = Entrez.esearch(db='pubmed',\n",
    "                                sort='relevance',\n",
    "                                retmax = 200000,\n",
    "                                retmode='xml',\n",
    "                                term=query)\n",
    "        results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        return results['IdList']\n",
    "    except Exception as e:\n",
    "        message = ' '.join(['An error occured when contacting NCBI servers.',\n",
    "                            'Check your query terms. Consider reattempting',\n",
    "                            'outside of peak hours. Message: \\n',\n",
    "                            f'{e}'])\n",
    "        print(message)\n",
    "        \n",
    "def fetch_details(target_ids, email):\n",
    "    \"\"\"\n",
    "    Queries IDs from PubMed\n",
    "    Automatically trims output to the Medline Citation\n",
    "\n",
    "    INPUTS:\n",
    "        Keyword (string): Keyword term\n",
    "        start_date (string): Date in YYYY/MM/DD format\n",
    "        end_date (string): Date in YYYY/MM/DD format\n",
    "        email (string): email address, required by NCBI\n",
    "    RETURNS:\n",
    "        results (list): list of MedlineCitation entries in each result\n",
    "        Prints error message and suggestions if error message from\n",
    "        NCBI\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        Entrez from BioPython\n",
    "    \"\"\"\n",
    "    Entrez.email = email\n",
    "    try:\n",
    "        handle = Entrez.efetch(db = 'pubmed',\n",
    "                            retmode = 'xml',\n",
    "                            id = target_ids)\n",
    "                            \n",
    "        results = [result['MedlineCitation'] for result in Entrez.read(handle)['PubmedArticle']]\n",
    "        handle.close()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        message = ' '.join(['An error occured when contacting NCBI servers.',\n",
    "                            'Check your query terms. Consider reattempting',\n",
    "                            'outside of peak hours. Message: \\n',\n",
    "                            f'{e}'])\n",
    "        print(message)\n",
    "\n",
    "def format_date(date_obj):\n",
    "    \"\"\"\n",
    "    Takes a date object and returns a formatted date time object\n",
    "\n",
    "    INPUTS:\n",
    "        date_obj (dict): Dictionary, which may contain keys\n",
    "                        ['Year', 'Month', 'Day'] with single\n",
    "                        string content.\n",
    "                        'Year' is expected to be 4 digit, if exists\n",
    "                        'Month' is expected to be 2 digit or\n",
    "                                3 character string, if exists\n",
    "                        'Day' is expected to be 2 digit, if exists\n",
    "    RETURNS:\n",
    "        date (date): Date, with missing/invalid month or day\n",
    "                     rounded to '01'.\n",
    "                     Returns an empty string if invalid, or \n",
    "                     no year.\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        datetime.datetime as dt\n",
    "    \"\"\"\n",
    "    # Dictionary to translate string months\n",
    "    months_dict = {\n",
    "                'jan': '01', 'feb': '02', 'mar': '03', \n",
    "                'apr': '04', 'may': '05', 'jun': '06' ,\n",
    "                'jul': '07', 'aug': '08', 'sep': '09', \n",
    "                'oct': '10', 'nov': '11', 'dec': '12',\n",
    "                }\n",
    "\n",
    "    # YEAR\n",
    "    if 'Year' in date_obj.keys():\n",
    "        year = date_obj['Year'].lower().strip()\n",
    "        if len(year) < 4 or not year.isdigit():\n",
    "            year = False\n",
    "    else:\n",
    "        year = False\n",
    "    # MONTH\n",
    "    if 'Month' in date_obj.keys():\n",
    "        month = date_obj['Month'].lower().strip()\n",
    "        if not month.isdigit() and month in months_dict.keys():\n",
    "            month = months_dict[month]\n",
    "        elif month.isdigit() and int(month) in range(1,13) and len(month) < 2:\n",
    "            month = '0' + str(int(month))\n",
    "        else:\n",
    "            month = False\n",
    "    else:\n",
    "        month = False\n",
    "    # DAY\n",
    "    if 'Day' in date_obj.keys():\n",
    "        day = date_obj['Day'].lower().strip()\n",
    "        if day.isdigit() and int(day) in range(1,13) and len(day) < 2:\n",
    "            day = '0' + str(int(day))\n",
    "        else:\n",
    "            day = False\n",
    "    else:\n",
    "        day = False\n",
    "\n",
    "    # Format\n",
    "    if year and month and day:\n",
    "        date = dt.strptime(f'{year}/{month}/{day}', r'%Y/%m/%d').date()\n",
    "    elif year and month:\n",
    "        date = dt.strptime(f'{year}/{month}', r'%Y/%m').date()\n",
    "    elif year and day:\n",
    "        date = dt.strptime(f'{year}/{day}', r'%Y/%d').date()\n",
    "    elif year:\n",
    "        date = dt.strptime(f'{year}', r'%Y').date()\n",
    "    else:\n",
    "        date = ''\n",
    "\n",
    "    # Return\n",
    "    return date\n",
    "\n",
    "def format_author(record, delimiter = '+'):\n",
    "    \"\"\"\n",
    "    Formats an Author from a PubMed Author List into a string\n",
    "    in 'FIRST (delimiter) LAST (delimiter) INITIALS' format,\n",
    "    all in lowercase\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): Single entry from a PubMed MedlineCitation \n",
    "                already sliced to ['Article']['AuthorList'].\n",
    "                Expected to potentially contain the single values\n",
    "                for keys []'ForeName', 'LastName', 'Initials']\n",
    "        delimiter (str): delimiter between components in the \n",
    "                output string. Default is '+' \n",
    "    RETURNS:\n",
    "        name_str (str): string listing of author name\n",
    "                missing fields are blank. If ForeName absent,\n",
    "                attempts to replace with Initials\n",
    "    \"\"\"\n",
    "    if 'ForeName' in record.keys() and len(record['ForeName']) > 0:\n",
    "        first_nm = record['ForeName'].lower().strip()\n",
    "    elif 'Initials' in record.keys() and len(record['Initials']) > 0:\n",
    "        first_nm = record['Initials'].lower().strip()\n",
    "    else:\n",
    "        first_nm = ''\n",
    "    if 'Initials' in record.keys() and len(record['Initials']) > 0:\n",
    "        initials = record['Initials'].lower().strip()\n",
    "    else:\n",
    "        initials = ''\n",
    "\n",
    "    if 'LastName' in record.keys() and len(record['LastName']) > 0:\n",
    "        last_nm = record['LastName'].lower().strip()\n",
    "    else:\n",
    "        last_nm = ''\n",
    "\n",
    "    name_str = delimiter.join([first_nm,last_nm,initials])\n",
    "\n",
    "    return name_str\n",
    "\n",
    "def journal_content(record, extract_date = False):\n",
    "    \"\"\"\n",
    "    Scrapes ['Article']['Journal'] level content from\n",
    "    a PubMed MedlineCitation entry:\n",
    "    Journal Title, Journal ISO Abbreviation, Volume, Issue,\n",
    "    and Publication Date\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): PubMed MedlineCitation already sliced to\n",
    "                ['Article']['Journal']\n",
    "        extract_date (bool): TRUE if extraction of date is\n",
    "                desired; default is FALSE \n",
    "    RETURNS:\n",
    "        jour_data (list): list of ['Journal'] data items;\n",
    "                [Journal Title, Journal ISO Abbreviation,\n",
    "                Volume, Issue, Publication Date]\n",
    "                missing fields are empty strings\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        format_date(): datetime.datetime as dt\n",
    "    \"\"\"\n",
    "    # JOURNAL NAME\n",
    "    if 'Title' in record.keys() and len(record['Title']) >0:\n",
    "        jour_title = str(record['Title']).lower().strip()\n",
    "    else:\n",
    "        jour_title = ''\n",
    "\n",
    "    # JOURNAL ABBREVIATION\n",
    "    if 'ISOAbbreviation' in record.keys() and len(record['ISOAbbreviation']) >0:\n",
    "        jour_abbrev = str(record['ISOAbbreviation']).lower().strip()\n",
    "    else:\n",
    "        jour_abbrev = ''\n",
    "\n",
    "    # Journal Issue Items\n",
    "    if 'JournalIssue' in record.keys():\n",
    "    # JOURNAL ISSUE\n",
    "        if 'Issue' in record['JournalIssue'].keys() and len(record['JournalIssue']['Issue']) >0:\n",
    "            jour_issue = str(record['JournalIssue']['Issue']).lower().strip()\n",
    "        else:\n",
    "            jour_issue = ''\n",
    "    # JOURNAL VOLUME\n",
    "        if 'Volume' in record['JournalIssue'].keys() and len(record['JournalIssue']['Volume']) >0:\n",
    "            jour_vol = str(record['JournalIssue']['Volume']).lower().strip()\n",
    "        else:\n",
    "            jour_vol = ''\n",
    "    # JOURNAL DATE\n",
    "        if extract_date:\n",
    "            if 'PubDate' in record['JournalIssue'].keys() and len(record['JournalIssue']['PubDate']) >0:\n",
    "                jour_date = format_date(record['JournalIssue']['PubDate'])\n",
    "            else:\n",
    "                jour_date = ''\n",
    "        else:\n",
    "            jour_date = ''\n",
    "    else:\n",
    "        jour_vol = ''\n",
    "        jour_issue = ''\n",
    "        jour_date = ''\n",
    "\n",
    "    jour_data = [jour_title, jour_abbrev, jour_vol, jour_issue, jour_date]\n",
    "\n",
    "    return jour_data\n",
    "\n",
    "def article_content(record, delimiter_btwn = '+', delimiter_within = ';;', \n",
    "                    date_format = r'%Y/%m/%d'):\n",
    "    \"\"\"\n",
    "    Scrapes ['Article'] level content from\n",
    "    a PubMed MedlineCitation entry:\n",
    "    Title, Abstract, Pageination, Publication Date, Language,\n",
    "    Authors, Journal Title, Journal ISO Abbreviation,\n",
    "    Journal Volume, Journal Issue.\n",
    "    Prefers JOURNAL PUBLICATION DATE over Article Date, if\n",
    "    it is present.\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): PubMed MedlineCitation already sliced to\n",
    "                ['Article']\n",
    "        delimiter_btwn (str): delimiter betwen authors in the\n",
    "                author list; default is '+'\n",
    "        delimiter_within (str): delimiter betwen components\n",
    "                of author name, used in format_author(); \n",
    "                default is ';;'\n",
    "        date_format (str): string for date format using datetime\n",
    "                object. Default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "    RETURNS:\n",
    "        article_data (list): list of ['Article'] data items;\n",
    "                [Article Title, Article Abstract, Publication Date,\n",
    "                Start Page, End Page, Language, Authors, Journal Title,\n",
    "                Journal ISO Abbreviation, Journal Volume, Journal Issue]\n",
    "                Missing fields are empty strings\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        datetime.datetime as dt\n",
    "        format_date()\n",
    "        format_author(): re\n",
    "        journal_content()\n",
    "    \"\"\"\n",
    "\n",
    "    # TITLE\n",
    "    if 'ArticleTitle' in record.keys() and len(record['ArticleTitle']) >0:\n",
    "        title = str(record['ArticleTitle']).lower().strip()\n",
    "    else:\n",
    "        title = ''\n",
    "\n",
    "    # ABSTRACT\n",
    "    if 'Abstract' in record.keys() and len(record['Abstract']) >0:\n",
    "        if 'AbstractText' in record['Abstract'].keys() and len(record['Abstract']['AbstractText']) > 0:\n",
    "            abstract = ' '.join(record['Abstract']['AbstractText'])\n",
    "        else:\n",
    "            abstract = ''\n",
    "    else:\n",
    "        abstract = ''\n",
    "\n",
    "    # DATE (IF NOT WITH JOURNAL)\n",
    "    if 'ArticleDate' in record.keys() and len(record['ArticleDate']) >0:\n",
    "        date = format_date(record['ArticleDate'][0])\n",
    "    else:\n",
    "        date = ''\n",
    "\n",
    "    # PAGINATION\n",
    "    pgn_regex = r'^([0-9a-z]+)(?:[ -:/]+?)([0-9a-z]+)$'\n",
    "    if 'Pagination' in record.keys() and len(record['Pagination']) >0:\n",
    "        if 'StartPage' in record['Pagination'].keys() and len(record['Pagination']['StartPage']) > 0:\n",
    "            page_start = record['Pagination']['StartPage']\n",
    "        else:\n",
    "            page_start = False\n",
    "        if 'EndPage' in record['Pagination'].keys() and len(record['Pagination']['EndPage']) > 0:\n",
    "            page_end = record['Pagination']['EndPage']\n",
    "        else:\n",
    "            page_end = False\n",
    "        if not (page_start or page_end):\n",
    "            if 'MedlinePgn' in record['Pagination'].keys() and len(record['Pagination']['MedlinePgn']) > 0:\n",
    "                search = re.search(pgn_regex, record['Pagination']['MedlinePgn'])\n",
    "                if search:\n",
    "                    page_start = search[1]\n",
    "                    page_end = search[2]\n",
    "        # If still not valid, just make empty strings\n",
    "        if not (page_start or page_end):\n",
    "            page_start = ''\n",
    "            page_end = ''\n",
    "    else:\n",
    "        page_start = ''\n",
    "        page_end = ''\n",
    "\n",
    "\n",
    "    # AUTHORS\n",
    "    if 'AuthorList' in record.keys() and len(record['AuthorList']) > 0:\n",
    "        authors = delimiter_btwn.join([format_author(author, delimiter_within) for author in record['AuthorList']])\n",
    "    else:\n",
    "        authors = ''\n",
    "\n",
    "    # LANGUAGE\n",
    "    if 'Language' in record.keys() and len(record['Language']) > 0:\n",
    "        lang = ', '.join(record['Language'])\n",
    "    else:\n",
    "        lang = ''\n",
    "\n",
    "    # ['Journal'] CONTENT\n",
    "    jour_content = journal_content(record['Journal'], extract_date = True)\n",
    "    jour_title, jour_abbrev, jour_vol, jour_issue, jour_date = jour_content\n",
    "\n",
    "    # PREFER DATE FROM JOURNAL\n",
    "    if jour_date != '':\n",
    "        date = jour_date\n",
    "    if date != '':\n",
    "        date = date.strftime(date_format)\n",
    "\n",
    "    # Package Output\n",
    "\n",
    "    article_content = [title, abstract, date, page_start,\n",
    "                        page_end, lang, authors, jour_title, \n",
    "                        jour_abbrev, jour_vol, jour_issue\n",
    "                        ]\n",
    "    # Return Output\n",
    "    return article_content\n",
    "\n",
    "def scrape_record(record, name_delim_btwn = '+', name_delim_within = ';;', \n",
    "                  date_format = r'%Y/%m/%d'):\n",
    "    \"\"\"\n",
    "    Scrapes a MedlineCitation of a PubMed article.\n",
    "    Returns article data as a list, which can become a single row \n",
    "    of a dataframe or other structure.\n",
    "\n",
    "    INPUTS:\n",
    "        record (dict): PubMed MedlineCitation\n",
    "        name_delimi_btwn (str): delimiter betwen authors in the\n",
    "                author list, used in article_content(); \n",
    "                default is '+'\n",
    "        name_delim_within (str): delimiter betwen components\n",
    "                of author name, used in format_author() within\n",
    "                article_content(); default is ';;'\n",
    "        date_format (str): string for date format using datetime\n",
    "                object in article_content(); \n",
    "                default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "    RETURNS:\n",
    "        content (list): list of article data;\n",
    "                [PMID, Publication Date, Article Title,\n",
    "                Journal Title, Journal ISO Abbreviation, \n",
    "                Journal Volume, Journal Issue, Keywords, \n",
    "                Authors, Language, Pagination (Start),\n",
    "                Pagination (End), Abstract]\n",
    "                Missing fields are empty strings\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        datetime.datetime as dt\n",
    "        format_date()\n",
    "        format_author(): re\n",
    "        journal_content()\n",
    "        article_content()\n",
    "    \"\"\"\n",
    "    # PMID\n",
    "    if 'PMID' in record.keys() and len(record['PMID']) > 0:\n",
    "        pmid = str(record['PMID']).lower().strip()\n",
    "    else:\n",
    "        pmid = ''\n",
    "    # KEYWORDS\n",
    "    if 'KeywordList' in record.keys() and len(record['KeywordList']) > 0:\n",
    "        keywords = name_delim_btwn.join([', '.join(keywords) for keywords in record['KeywordList']])\n",
    "    else:\n",
    "        keywords = ''\n",
    "\n",
    "    # ARTICLE CONTENT\n",
    "    article = [i for i in article_content(record['Article'], name_delim_btwn, name_delim_within, date_format)]\n",
    "    title, abstract, date, page_start = article[0:4]\n",
    "    page_end, lang, authors, jour_title = article[4:8]\n",
    "    jour_abbrev, jour_vol, jour_issue = article[8:11]\n",
    "\n",
    "    # Organize Output into row\n",
    "    content = [pmid, date, title, jour_title, jour_abbrev,\n",
    "            jour_vol, jour_issue, keywords, authors,\n",
    "            lang, page_start, page_end, abstract]\n",
    "    \n",
    "    # Return\n",
    "    return content\n",
    "\n",
    "def chunk_process(keyword, start_date, end_date, email, \n",
    "                  path, chunksize = 100, date_format = r'%Y/%m/%d',\n",
    "                  name_delim_btwn = '+', name_delim_within = ';;', \n",
    "                  delim = ',', quote_str = '|', overwrite = False):\n",
    "    \"\"\"\n",
    "    Performs a search of PubMed using a date range and keyword,\n",
    "    and scrapes these records into a CSV file.\n",
    "\n",
    "    INPUTS:\n",
    "        keyword (string): Keyword term\n",
    "        start_date (string): Date in YYYY/MM/DD format\n",
    "        end_date (string): Date in YYYY/MM/DD format\n",
    "        email (string): email address, required by NCBI\n",
    "        path (string,path): string address of output file path\n",
    "        chunksize (int): number of records to batch process\n",
    "                between opening file, used to optimize run time\n",
    "                based on capabilities of an individual machine;\n",
    "                default is 100\n",
    "        date_format (str): string for date format using datetime\n",
    "                object in article_content(); \n",
    "                default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "        name_delimi_btwn (str): delimiter betwen authors in the\n",
    "                author list; \n",
    "                default is '+'\n",
    "        name_delim_within (str): delimiter betwen components\n",
    "                of author name; \n",
    "                default is ';;'\n",
    "        delim (str): delimiter between values in a single row\n",
    "                in the CSV output file. Must be a single\n",
    "                character string;\n",
    "                default is ','\n",
    "        quote_str (str): character used to quote entries that\n",
    "                contain characters in the delimiters;\n",
    "                default is '|'\n",
    "        overwrite (bool): True/False value indicating if it is\n",
    "                desired to overwrite the output file, if it\n",
    "                already exists;\n",
    "                default is FALSE\n",
    "\n",
    "    RETURNS:\n",
    "        writes records to `path`. Prints happy message summary\n",
    "        if successful. If error, prints error message and the row\n",
    "        where the problem occured.\n",
    "\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        os\n",
    "        csv\n",
    "        re\n",
    "        Entrez from BioPython\n",
    "        datetime.datetime as dt\n",
    "        pubmed_search_ids()\n",
    "        scrape_record()\n",
    "        journal_content()\n",
    "        article_content()\n",
    "        format_date()\n",
    "        format_author()\n",
    "    \"\"\"  \n",
    "    # Perform Search, Get IDS\n",
    "    target_ids = pubmed_search_ids(keyword, start_date, end_date, email)\n",
    "    # Chunk Data\n",
    "    if target_ids:\n",
    "        try:\n",
    "            for i in range (0, len(target_ids), chunksize):\n",
    "                chunk_ids = target_ids[i:i+chunksize]\n",
    "                records = fetch_details(chunk_ids, email)\n",
    "                data = [scrape_record(record,name_delim_btwn, name_delim_within, date_format) for record in records]\n",
    "                # If output file does not exist or overwrite = 'TRUE was called, create file\n",
    "                if not os.path.isfile(path) or overwrite:\n",
    "                    with open(path, 'w', encoding = 'utf-8') as outfile:\n",
    "                        csvwriter = csv.writer(outfile, delimiter = delim, quotechar = quote_str)\n",
    "                        for row in data:\n",
    "                            csvwriter.writerow(row)\n",
    "                # Otherwise, open for appending\n",
    "                else:\n",
    "                    with open(path,'a', encoding = 'utf-8') as outfile:\n",
    "                        csvwriter = csv.writer(outfile, delimiter = delim, quotechar = quote_str)\n",
    "                        for row in data:\n",
    "                            csvwriter.writerow(row)\n",
    "            # Happy Message\n",
    "            message = [f'Success! \\n {len(target_ids)} records for ',\n",
    "                    'PubMed Search: \\n',\n",
    "                    f'({keyword}) AND (\"{start_date}\"[Date - Publication]'\n",
    "                    f' : \"{end_date}\"[Date - Publication]) \\n',\n",
    "                    f' written to {path}']\n",
    "            print(''.join(message))\n",
    "        except Exception as e:\n",
    "            message = ['An error occured:', e, \n",
    "                    'Row with issue:', f'{row}']\n",
    "            print('\\n'.join(message))\n",
    "\n",
    "def scrapper(keyword = None, start_date = None, end_date = None,\n",
    "                    email = None, path = None, chunksize = 100,\n",
    "                    date_format = r'%Y/%m/%d',\n",
    "                    name_delim_btwn = '+', name_delim_within = ';;', \n",
    "                    delim = ',', quote_str = '|', overwrite = False):\n",
    "    \"\"\"\n",
    "    Validates inputs and runs scrapper!\n",
    "\n",
    "    INPUTS:\n",
    "        PROMPTS FOR INPUT IF MISSING OR INVALID:\n",
    "            keyword (string): Keyword term\n",
    "            start_date (string): Date in YYYY/MM/DD format\n",
    "            end_date (string): Date in YYYY/MM/DD format\n",
    "            email (string): email address, required by NCBI\n",
    "            path (string,path): string address of output file path\n",
    "        DOES NOT PROMPT OR VALIDATE, HAS DEFAULT:\n",
    "            chunksize (int): number of records to batch process\n",
    "                    between opening file, used to optimize run time\n",
    "                    based on capabilities of an individual machine;\n",
    "                    default is 100\n",
    "            date_format (str): string for date format using datetime\n",
    "                    object in article_content(); \n",
    "                    default is '%Y/%m/%d' for YYYY/MM/DD format\n",
    "            name_delimi_btwn (str): delimiter betwen authors in the\n",
    "                    author list; \n",
    "                    default is '+'\n",
    "            name_delim_within (str): delimiter betwen components\n",
    "                    of author name; \n",
    "                    default is ';;'\n",
    "            delim (str): delimiter between values in a single row\n",
    "                    in the CSV output file. Must be a single\n",
    "                    character string;\n",
    "                    default is ','\n",
    "            quote_str (str): character used to quote entries that\n",
    "                    contain characters in the delimiters;\n",
    "                    default is '|'\n",
    "            overwrite (bool): True/False value indicating if it is\n",
    "                    desired to overwrite the output file, if it\n",
    "                    already exists;\n",
    "                    default is FALSE\n",
    "    RETURNS:\n",
    "        writes records to `path`. Prints happy message summary\n",
    "        if successful. If error, prints error message and the row\n",
    "        where the problem occured.\n",
    "\n",
    "    REQUIREMENTS/DEPENDENCIES:\n",
    "        os\n",
    "        csv\n",
    "        re\n",
    "        Entrez from BioPython\n",
    "        datetime from datetime as dt\n",
    "        chunk_process()\n",
    "        pubmed_search_ids()\n",
    "        scrape_record()\n",
    "        journal_content()\n",
    "        article_content()\n",
    "        format_date()\n",
    "        format_author()\n",
    "    \"\"\"\n",
    "    ########### DATA CHECKS ################\n",
    "    # =======================================      \n",
    "    email_regex = r\"^[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?$\"\n",
    "    # Allow user to exit\n",
    "    quit = False\n",
    "    while not quit:\n",
    "        ###### GET INPUTS IF NOT GIVEN IN FUNCTION\n",
    "        while not email:\n",
    "            email = input(\"Enter email for Entrez query, or 'q' to exit: \").lower().strip()\n",
    "            if email == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        if not keyword:\n",
    "            keyword = input(\"Enter keyword, or 'q' to exit: \").lower().strip()\n",
    "            if keyword == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        while not start_date:\n",
    "            start_date = input(\"Enter start date (YYYY/MM/DD), or 'q' to exit: \").strip().lower()\n",
    "            if start_date == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        while not end_date:\n",
    "            end_date = input(\"Enter end date (YYYY/MM/DD), or 'q' to exit: \").strip().lower()\n",
    "            if end_date == 'q':\n",
    "                quit = True\n",
    "                break\n",
    "        while not path:\n",
    "            # No .lower() because paths can be case sensitive\n",
    "            path = input(\"Enter path for output file (.txt or .csv), or 'q' to exit: \").strip()\n",
    "            if path == 'q' or 'Q':\n",
    "                quit = True\n",
    "                break\n",
    "        ###### VALIDATE\n",
    "        if email:\n",
    "            if not re.search(email_regex, email):\n",
    "                print(\"Invalid email.\")\n",
    "                email = None\n",
    "        if start_date:\n",
    "        # Checks start_date format, if this fails, it's invalid\n",
    "            try:\n",
    "                start_date = dt.strptime(start_date, r'%Y/%m/%d').date()\n",
    "            except:\n",
    "                print(\"Invalid start date.\")\n",
    "                start_date = None\n",
    "        if end_date:\n",
    "        # Checks end_date format, if this fails, it's invalid\n",
    "            try:\n",
    "                end_date = dt.strptime(end_date, r'%Y/%m/%d').date()\n",
    "            except:\n",
    "                print(\"Invalid date. Try again\")\n",
    "                end_date = None\n",
    "        # Ensure start_date is before end_date\n",
    "        if (start_date and end_date) and start_date > end_date:\n",
    "            print(f\"Start Date {start_date} is after {end_date}. Please enter valid dates\")\n",
    "            start_date = None\n",
    "            end_date = None\n",
    "        # Check path is valid\n",
    "        if path:\n",
    "            try:\n",
    "                path = os.path.abspath(path)\n",
    "                if not os.path.isdir(os.path.split(path)[0]):\n",
    "                    print(\"Path directory not found.\")\n",
    "                    path = None\n",
    "                if os.path.basename(path).split('.')[1] not in ('txt', 'csv'):\n",
    "                    print(\"File must have a .txt or .csv extension.\")\n",
    "                    path = None\n",
    "            except:\n",
    "                print(\"Invalid path\")\n",
    "                path = None\n",
    "        # Ensure String Format for dates\n",
    "        if start_date and end_date:\n",
    "            if not isinstance(start_date,str):\n",
    "                start_date = start_date.strftime(r'%Y/%m/%d')\n",
    "            if not isinstance(end_date, str):\n",
    "                end_date = end_date.strftime(r'%Y/%m/%d')\n",
    "        \n",
    "        # If all valid, break out of validation cycle!\n",
    "        if start_date and end_date and keyword and email and path:\n",
    "            break\n",
    "    if not quit:\n",
    "        chunk_process(keyword, start_date, end_date, email, \n",
    "                  path, chunksize, date_format,\n",
    "                  name_delim_btwn, name_delim_within, \n",
    "                  delim, quote_str, overwrite)\n",
    "    else:\n",
    "        print(\"Processing Stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
